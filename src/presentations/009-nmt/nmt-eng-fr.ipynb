{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33b6abe6-d734-48d1-a539-4da1e33edc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Dense, Embedding, Dropout, MultiHeadAttention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "import re\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aa92ecf-e497-443e-91d6-550c53152f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 'sethjsa/medline_en_fr_parallel_doc' dataset from Hugging Face...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d935c123f4a4ce1bf79453413b7d64a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/302 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d51ee51c43a4933aa02f51216487964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/1.30M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664ad167be61428db49d66c6bae66e3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 800 examples from the dataset.\n",
      "\n",
      "--- Inspecting first example structure from Hugging Face dataset ---\n",
      "Type of first_example: <class 'dict'>\n",
      "Keys of first_example: dict_keys(['fr', 'en'])\n",
      "'translation' key NOT found in first_example.\n",
      "--- End Inspection ---\n",
      "Loaded 800 parallel sentences.\n"
     ]
    }
   ],
   "source": [
    "# --- Hugging Face Dataset Import ---\n",
    "from datasets import load_dataset\n",
    "\n",
    "# --- 1. Data Acquisition and Preprocessing ---\n",
    "\n",
    "# Recommended Lightweight Dataset: 'small_parallel_en-fr' from Hugging Face\n",
    "# This dataset is specifically designed for English-French translation.\n",
    "# We'll load a small portion of the training set to keep it manageable for a \"simple\" LLM.\n",
    "try:\n",
    "    print(\"Loading 'sethjsa/medline_en_fr_parallel_doc' dataset from Hugging Face...\")\n",
    "    # Load the full DatasetDict first\n",
    "    # This will return {'train': Dataset object}\n",
    "    # dataset = load_dataset('sethjsa/wmt_en_fr_parallel', split='train[:5000]') \n",
    "    dataset_dict = load_dataset(\"sethjsa/medline_en_fr_parallel_doc\")\n",
    "    # Select the 'train' split and then slice it.\n",
    "    train_split_size = len(dataset_dict['train'])\n",
    "    num_examples_to_load = min(800, train_split_size) # Load up to 100\n",
    "    dataset = dataset_dict['train'].select(range(num_examples_to_load))\n",
    "    print(f\"Loading {num_examples_to_load} examples from the dataset.\")\n",
    "    \n",
    "    \n",
    "\n",
    "     # --- DEBUGGING START ---\n",
    "    print(\"\\n--- Inspecting first example structure from Hugging Face dataset ---\")\n",
    "    if len(dataset) > 0:\n",
    "        first_example = dataset[0]\n",
    "        print(f\"Type of first_example: {type(first_example)}\")\n",
    "        print(f\"Keys of first_example: {first_example.keys()}\")\n",
    "        \n",
    "        if 'translation' in first_example:\n",
    "            print(f\"Type of first_example['translation']: {type(first_example['translation'])}\")\n",
    "            if isinstance(first_example['translation'], dict):\n",
    "                print(f\"Keys of first_example['translation']: {first_example['translation'].keys()}\")\n",
    "                print(f\"Sample English: {first_example['translation']['en']}\")\n",
    "                print(f\"Sample French: {first_example['translation']['fr']}\")\n",
    "            else:\n",
    "                print(f\"first_example['translation'] is NOT a dict. Its value: {first_example['translation']}\")\n",
    "        else:\n",
    "            print(\"'translation' key NOT found in first_example.\")\n",
    "    else:\n",
    "        print(\"Dataset is empty.\")\n",
    "    print(\"--- End Inspection ---\")\n",
    "    # --- DEBUGGING END ---\n",
    "    \n",
    "    raw_en_sentences = [example['en'] for example in dataset]\n",
    "    raw_fr_sentences = [example['fr'] for example in dataset]\n",
    "    print(f\"Loaded {len(raw_en_sentences)} parallel sentences.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset from Hugging Face: {e}\")\n",
    "    print(\"Falling back to a very small illustrative dataset.\")\n",
    "    # Fallback to a tiny manual dataset if Hugging Face dataset loading fails\n",
    "    raw_en_sentences = [\n",
    "        \"I am a student.\",\n",
    "        \"How are you?\",\n",
    "        \"She likes cats.\",\n",
    "        \"We are learning machine translation.\",\n",
    "        \"The dog is brown.\",\n",
    "        \"He reads books.\",\n",
    "        \"Where is the library?\",\n",
    "        \"What is your name?\",\n",
    "        \"This is a test sentence.\",\n",
    "        \"Please translate this.\",\n",
    "        \"Hello world.\",\n",
    "        \"I love deep learning.\"\n",
    "    ]\n",
    "    raw_fr_sentences = [\n",
    "        \"Je suis étudiant.\",\n",
    "        \"Comment allez-vous ?\",\n",
    "        \"Elle aime les chats.\",\n",
    "        \"Nous apprenons la traduction automatique.\",\n",
    "        \"Le chien est marron.\",\n",
    "        \"Il lit des livres.\",\n",
    "        \"Où est la bibliothèque ?\",\n",
    "        \"Quel est votre nom ?\",\n",
    "        \"Ceci est une phrase test.\",\n",
    "        \"Veuillez traduire ceci.\",\n",
    "        \"Bonjour le monde.\",\n",
    "        \"J'adore l'apprentissage profond.\"\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0569ed08-85d8-4a0b-b2f7-c7395d8adaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example processed sentences:\n",
      "English: pmid 20847962  tl sedlak a pu e aymong m gao n khan h quan kh humphries sex differences in coronary catheterization and revascularization following acute myocardial infarction time trends from 1994 to 2003 in british columbia .  background  studies before the turn of the century reported sex differences in procedure rates . it is unknown whether these differences persist . objectives  to examine time trends and sex differences in coronary catheterization and revascularization following acute myocardial infarction ami . methods  a retrospective analysis was performed of all patients 20 years of age or older who were admitted to hospital in british columbia with an ami between april 1 1994 and march 31 2003 . segmented regression analysis was used to examine the inflection point of the time trend in 90day catheterization rates postami . multivariable cox regression modelling was used to evaluate sex differences in receiving catheterization and revascularization following ami . results  ninetyday coronary catheterization rates increased significantly over the study period for both men and women p0 .0001 for trend with a steeper increase beginning in september 2000 . women were less likely to undergo catheterization than men even after adjustment for baseline differences this sex effect was modified by age and care in the intensive care unit or cardiac care unit icuccu . specifically icuccu admission eliminated the sex difference among patients who were younger than 65 years of age . conditional on receiving cardiac catheterization postami female sex was not associated with a lower likelihood of receiving revascularization within one year hr 0 .96 95 ci 0 .91 to 1 .02 . conclusions  despite recent increases in catheterization rates postami women were less likely to undergo catheterization than men . interestingly access to icuccu care removed the sex difference in catheterization access in patients younger than 65 years of age .\n",
      "French input: <sos> pmid 20847962  tl sedlak a pu e aymong m gao n khan h quan kh humphries historique  les tudes menes au tournant du sicle faisaient tat de diffrences de taux dinterventions selon les sexes . on ne sait pas si ces diffrences persistent . objectifs  examiner les tendances dans le temps et les diffrences selon les sexes du cathtrisme coronarien et de la revascularisation aprs un infarctus aigu du myocarde iam . mthodologie  les chercheurs ont procd  une analyse rtrospective de tous les patients de 20 ans ou plus hospitaliss en colombiebritannique en raison dun iam entre le 1 avril 1994 et le 31 mars 2003 . lanalyse de rgression segmente a permis dexaminer le point dinflexion de la tendance dans le temps des taux de cathtrisme 90 jours aprs un iam . le modle de rgression de cox multivariable a permis dvaluer les diffrences dadministration de cathtrisme et de revascularisation selon les sexes aprs un iam . rsultats  les taux de cathtrismes coronaires au bout de 90 jours ont considrablement augment pendant la priode de ltude tant chez les hommes que chez les femmes p00001 en matire de tendance laugmentation tant plus marque  compter de septembre 2000 . les femmes taient moins susceptibles de subir un cathtrisme que les hommes mme aprs rajustement des diffrences de dpart .  cet effet attribuable au sexe changeait selon lge et les soins  lunit de soins intensifs ou de soins cardiaques usiusc . notamment lhospitalisation  lusiusc liminait la diffrence selon les sexes chez les patients de moins de 65 ans . sous rserve davoir reu un cathtrisme cardiaque aprs liam le sexe fminin ne sassociait pas  une diminution de la probabilit davoir reu une revascularisation au bout dun an fc 096 95  ic 091  102 . conclusions  malgr laugmentation rcente du taux de cathtrisme aprs un iam les femmes taient moins susceptibles de subir un cathtrisme que les hommes . fait intressant laccs  lusiusc faisait disparatre la diffrence daccs au cathtrisme chez les patients de moins de 65 ans .\n",
      "French output: pmid 20847962  tl sedlak a pu e aymong m gao n khan h quan kh humphries historique  les tudes menes au tournant du sicle faisaient tat de diffrences de taux dinterventions selon les sexes . on ne sait pas si ces diffrences persistent . objectifs  examiner les tendances dans le temps et les diffrences selon les sexes du cathtrisme coronarien et de la revascularisation aprs un infarctus aigu du myocarde iam . mthodologie  les chercheurs ont procd  une analyse rtrospective de tous les patients de 20 ans ou plus hospitaliss en colombiebritannique en raison dun iam entre le 1 avril 1994 et le 31 mars 2003 . lanalyse de rgression segmente a permis dexaminer le point dinflexion de la tendance dans le temps des taux de cathtrisme 90 jours aprs un iam . le modle de rgression de cox multivariable a permis dvaluer les diffrences dadministration de cathtrisme et de revascularisation selon les sexes aprs un iam . rsultats  les taux de cathtrismes coronaires au bout de 90 jours ont considrablement augment pendant la priode de ltude tant chez les hommes que chez les femmes p00001 en matire de tendance laugmentation tant plus marque  compter de septembre 2000 . les femmes taient moins susceptibles de subir un cathtrisme que les hommes mme aprs rajustement des diffrences de dpart .  cet effet attribuable au sexe changeait selon lge et les soins  lunit de soins intensifs ou de soins cardiaques usiusc . notamment lhospitalisation  lusiusc liminait la diffrence selon les sexes chez les patients de moins de 65 ans . sous rserve davoir reu un cathtrisme cardiaque aprs liam le sexe fminin ne sassociait pas  une diminution de la probabilit davoir reu une revascularisation au bout dun an fc 096 95  ic 091  102 . conclusions  malgr laugmentation rcente du taux de cathtrisme aprs un iam les femmes taient moins susceptibles de subir un cathtrisme que les hommes . fait intressant laccs  lusiusc faisait disparatre la diffrence daccs au cathtrisme chez les patients de moins de 65 ans . <eos>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add special tokens\n",
    "SOS_TOKEN = \"<sos>\" # Start of Sequence\n",
    "EOS_TOKEN = \"<eos>\" # End of Sequence\n",
    "UNK_TOKEN = \"<unk>\" # Unknown Token\n",
    "PAD_TOKEN = \"<pad>\" # Padding Token\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    # Add space before punctuation (adjust as needed for specific languages/punctuation)\n",
    "    sentence = re.sub(r'([.!?])', r' \\1', sentence) \n",
    "    # Remove characters that are not letters, punctuation, or spaces\n",
    "    sentence = re.sub(r'[^a-zA-Z0-9.!?\\s]', '', sentence) # Allow numbers for more general text\n",
    "    sentence = sentence.strip()\n",
    "    return sentence\n",
    "\n",
    "# Preprocess raw sentences\n",
    "en_sentences = [preprocess_sentence(s) for s in raw_en_sentences]\n",
    "fr_sentences = [preprocess_sentence(s) for s in raw_fr_sentences]\n",
    "\n",
    "# Add SOS and EOS tokens to French sentences for decoder input/target\n",
    "fr_sentences_in = [f\"{SOS_TOKEN} {s}\" for s in fr_sentences]\n",
    "fr_sentences_out = [f\"{s} {EOS_TOKEN}\" for s in fr_sentences]\n",
    "\n",
    "print(\"\\nExample processed sentences:\")\n",
    "print(\"English:\", en_sentences[0])\n",
    "print(\"French input:\", fr_sentences_in[0])\n",
    "print(\"French output:\", fr_sentences_out[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "700eeab7-4067-4cb1-a241-2598adaaec0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "English Vocab Size (including PAD): 16980\n",
      "French Vocab Size (including PAD): 19938\n",
      "Max English sequence length: 615\n",
      "Max French sequence length: 541\n",
      "Encoder Input Shape: (800, 615)\n",
      "Decoder Input Shape: (800, 541)\n",
      "Decoder Target Shape: (800, 541)\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "# Keras Tokenizer by default filters punctuation, which we've handled,\n",
    "# so we pass an empty filter string to keep our preprocessed tokens.\n",
    "# We also ensure UNK_TOKEN is handled.\n",
    "en_tokenizer = Tokenizer(filters='', oov_token=UNK_TOKEN)\n",
    "fr_tokenizer = Tokenizer(filters='', oov_token=UNK_TOKEN)\n",
    "\n",
    "# Fit on processed sentences including special tokens\n",
    "en_tokenizer.fit_on_texts(en_sentences)\n",
    "# Fit French tokenizer on both input and output sequences to ensure comprehensive vocabulary\n",
    "fr_tokenizer.fit_on_texts(fr_sentences_in + fr_sentences_out) \n",
    "\n",
    "# Ensure PAD_TOKEN is in the vocabulary and assigned ID 0 for easier masking\n",
    "# Adjust existing indices if 0 is already taken\n",
    "if PAD_TOKEN not in en_tokenizer.word_index:\n",
    "    en_tokenizer.word_index[PAD_TOKEN] = 0 # Assign ID 0 to PAD_TOKEN\n",
    "    # Shift other indices if 0 was previously assigned to another word\n",
    "    for word, idx in list(en_tokenizer.word_index.items()):\n",
    "        if idx == 0 and word != PAD_TOKEN:\n",
    "            en_tokenizer.word_index[word] = len(en_tokenizer.word_index)\n",
    "            break\n",
    "if PAD_TOKEN not in fr_tokenizer.word_index:\n",
    "    fr_tokenizer.word_index[PAD_TOKEN] = 0 # Assign ID 0 to PAD_TOKEN\n",
    "    for word, idx in list(fr_tokenizer.word_index.items()):\n",
    "        if idx == 0 and word != PAD_TOKEN:\n",
    "            fr_tokenizer.word_index[word] = len(fr_tokenizer.word_index)\n",
    "            break\n",
    "\n",
    "# Rebuild index_word maps after potentially adjusting word_index\n",
    "en_tokenizer.index_word = {idx: word for word, idx in en_tokenizer.word_index.items()}\n",
    "fr_tokenizer.index_word = {idx: word for word, idx in fr_tokenizer.word_index.items()}\n",
    "\n",
    "\n",
    "# Convert text to sequences of integers\n",
    "encoder_input_sequences = en_tokenizer.texts_to_sequences(en_sentences)\n",
    "decoder_input_sequences = fr_tokenizer.texts_to_sequences(fr_sentences_in)\n",
    "decoder_target_sequences = fr_tokenizer.texts_to_sequences(fr_sentences_out)\n",
    "\n",
    "# Calculate vocabulary sizes (including 0 for padding)\n",
    "en_vocab_size = len(en_tokenizer.word_index)\n",
    "fr_vocab_size = len(fr_tokenizer.word_index)\n",
    "\n",
    "print(f\"\\nEnglish Vocab Size (including PAD): {en_vocab_size}\")\n",
    "print(f\"French Vocab Size (including PAD): {fr_vocab_size}\")\n",
    "\n",
    "# Padding\n",
    "# It's important for Transformer models to have fixed-length inputs for batching.\n",
    "# We use 'post' padding, adding zeros at the end.\n",
    "max_en_len = max(len(s) for s in encoder_input_sequences) if encoder_input_sequences else 1\n",
    "max_fr_len = max(len(s) for s in decoder_input_sequences) if decoder_input_sequences else 1\n",
    "\n",
    "encoder_input_data = pad_sequences(encoder_input_sequences, maxlen=max_en_len, padding='post', value=0)\n",
    "decoder_input_data = pad_sequences(decoder_input_sequences, maxlen=max_fr_len, padding='post', value=0)\n",
    "decoder_target_data = pad_sequences(decoder_target_sequences, maxlen=max_fr_len, padding='post', value=0)\n",
    "\n",
    "print(f\"Max English sequence length: {max_en_len}\")\n",
    "print(f\"Max French sequence length: {max_fr_len}\")\n",
    "print(f\"Encoder Input Shape: {encoder_input_data.shape}\")\n",
    "print(f\"Decoder Input Shape: {decoder_input_data.shape}\")\n",
    "print(f\"Decoder Target Shape: {decoder_target_data.shape}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb4ea04-35cd-4e12-b54e-ee631550db8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Define the Transformer Architecture (Encoder-Decoder) ---\n",
    "\n",
    "class PositionalEncoding(Layer):\n",
    "    def __init__(self, position, d_model, **kwargs):\n",
    "        super(PositionalEncoding, self).__init__(**kwargs)\n",
    "        self.position = position\n",
    "        self.d_model = d_model\n",
    "        # self.pos_encoding = self._get_angles(np.arange(position)[np.newaxis, :],\n",
    "        #                                      np.arange(d_model)[np.newaxis, :])\n",
    "        self.pos_encoding = self._get_angles(np.arange(position)[:, np.newaxis], # Make it a column vector\n",
    "                                     np.arange(d_model)[np.newaxis, :])  # Make it a row vector\n",
    "        self.pos_encoding = tf.cast(self.pos_encoding, dtype=tf.float32)\n",
    "\n",
    "    def _get_angles(self, position, i):\n",
    "        angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(self.d_model))\n",
    "        return position * angle_rates\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        return inputs + self.pos_encoding[:seq_len, :]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"position\": self.position,\n",
    "            \"d_model\": self.d_model,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "def create_padding_mask(seq):\n",
    "    # This mask is for padding tokens (value 0). It will be 1 where there is padding.\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "\n",
    "def create_look_ahead_mask(seq_len):\n",
    "    # This mask is to prevent a token from attending to future tokens in the sequence.\n",
    "    # It will be 1 for future tokens.\n",
    "    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "    return look_ahead_mask  # (seq_len, seq_len)\n",
    "\n",
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask (for self-attention in encoder)\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    # Decoder look-ahead mask (for masked self-attention in decoder)\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    # Decoder target padding mask (for masked self-attention in decoder, combines with look-ahead)\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask) # Combine to mask both future and padding\n",
    "    \n",
    "    # Decoder padding mask (for cross-attention in decoder, attends to encoder output)\n",
    "    # This is the same as enc_padding_mask because it masks the *encoder output* (source sequence)\n",
    "    # based on its padding.\n",
    "    dec_padding_mask = create_padding_mask(inp) \n",
    "  \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
    "\n",
    "\n",
    "class EncoderLayer(Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, **kwargs):\n",
    "        super(EncoderLayer, self).__init__(**kwargs)\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(dff, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        \n",
    "        # Store parameters for get_config\n",
    "        self.d_model_param = d_model\n",
    "        self.num_heads_param = num_heads\n",
    "        self.dff_param = dff\n",
    "        self.rate_param = rate\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        # Self-attention\n",
    "        attn_output = self.mha(x, x, x, attention_mask=mask) \n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"d_model\": self.d_model_param,\n",
    "            \"num_heads\": self.num_heads_param,\n",
    "            \"dff\": self.dff_param,\n",
    "            \"rate\": self.rate_param,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class DecoderLayer(Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1, **kwargs):\n",
    "        super(DecoderLayer, self).__init__(**kwargs)\n",
    "        self.mha1 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads) # Masked self-attention\n",
    "        self.mha2 = MultiHeadAttention(num_heads=num_heads, key_dim=d_model // num_heads) # Cross-attention\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(dff, activation='relu'),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(rate)\n",
    "        self.dropout2 = Dropout(rate)\n",
    "        self.dropout3 = Dropout(rate)\n",
    "        \n",
    "        # Store parameters for get_config\n",
    "        self.d_model_param = d_model\n",
    "        self.num_heads_param = num_heads\n",
    "        self.dff_param = dff\n",
    "        self.rate_param = rate\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        # Masked self-attention (attends to its own previous outputs)\n",
    "        attn1 = self.mha1(x, x, x, attention_mask=look_ahead_mask) \n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(x + attn1)\n",
    "\n",
    "        # Cross-attention (attends to encoder output)\n",
    "        attn2 = self.mha2(out1, enc_output, enc_output, attention_mask=padding_mask) \n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2)\n",
    "\n",
    "        # Feed-forward network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        return self.layernorm3(out2 + ffn_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"d_model\": self.d_model_param,\n",
    "            \"num_heads\": self.num_heads_param,\n",
    "            \"dff\": self.dff_param,\n",
    "            \"rate\": self.rate_param,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class Encoder(Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1, **kwargs):\n",
    "        super(Encoder, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(maximum_position_encoding, d_model)\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(rate)\n",
    "        \n",
    "        # Store parameters for get_config\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.maximum_position_encoding = maximum_position_encoding\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # Scale embeddings\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)\n",
    "        return x\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"d_model\": self.d_model,\n",
    "            \"num_heads\": self.enc_layers[0].num_heads_param, # Access from first layer's stored param\n",
    "            \"dff\": self.enc_layers[0].dff_param,\n",
    "            \"input_vocab_size\": self.input_vocab_size,\n",
    "            \"maximum_position_encoding\": self.maximum_position_encoding,\n",
    "            \"rate\": self.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "class Decoder(Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1, **kwargs):\n",
    "        super(Decoder, self).__init__(**kwargs)\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = PositionalEncoding(maximum_position_encoding, d_model)\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
    "        self.dropout = Dropout(rate)\n",
    "        \n",
    "        # Store parameters for get_config\n",
    "        self.target_vocab_size = target_vocab_size\n",
    "        self.maximum_position_encoding = maximum_position_encoding\n",
    "        self.rate = rate\n",
    "\n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32)) # Scale embeddings\n",
    "        x = self.pos_encoding(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output=enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=padding_mask)\n",
    "        return x\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"d_model\": self.d_model,\n",
    "            \"num_heads\": self.dec_layers[0].num_heads_param,\n",
    "            \"dff\": self.dec_layers[0].dff_param,\n",
    "            \"target_vocab_size\": self.target_vocab_size,\n",
    "            \"maximum_position_encoding\": self.maximum_position_encoding,\n",
    "            \"rate\": self.rate,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "331a3893-eea6-4844-855c-1be5be839928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Training ---\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-15 11:48:20.795306: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-06-15 11:48:31.961391: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 74926336 exceeds 10% of free system memory.\n",
      "2025-06-15 11:48:31.961482: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 96825600 exceeds 10% of free system memory.\n",
      "2025-06-15 11:48:32.182884: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 96825600 exceeds 10% of free system memory.\n",
      "2025-06-15 11:48:32.338631: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 85175040 exceeds 10% of free system memory.\n",
      "2025-06-15 11:48:32.476400: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 74926336 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 3s/step - accuracy_function: 7.5377e-06 - loss: 9.8987\n",
      "Epoch 2/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 3s/step - accuracy_function: 0.0034 - loss: 9.8389\n",
      "Epoch 3/50\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 3s/step - accuracy_function: 0.0431 - loss: 9.6923\n",
      "Epoch 4/50\n",
      "\u001b[1m12/50\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:53\u001b[0m 5s/step - accuracy_function: 0.0486 - loss: 9.5157"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 114\u001b[0m\n\u001b[1;32m    111\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m \u001b[38;5;66;03m# Batch size can be larger now due to more data\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Starting Training ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 114\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mencoder_input_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_input_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_target_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m    120\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Training Complete ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# --- 4. Inference (Translation) ---\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:377\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    376\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 377\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/Code/mtech/deep_learning/.venv/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class Transformer(Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "                 input_vocab_size, target_vocab_size,\n",
    "                 pe_input, pe_target, rate=0.1, **kwargs):\n",
    "        super(Transformer, self).__init__(**kwargs)\n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                               target_vocab_size, pe_target, rate)\n",
    "        self.final_layer = Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        inp, tar = inputs # inp = encoder_input, tar = decoder_input\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "\n",
    "        enc_output = self.encoder(inp, training=training, mask=enc_padding_mask)  \n",
    "        dec_output = self.decoder(tar, enc_output, training=training, look_ahead_mask=look_ahead_mask, padding_mask=dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output) \n",
    "        return final_output\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"num_layers\": self.encoder.num_layers, \n",
    "            \"d_model\": self.encoder.d_model,\n",
    "            \"num_heads\": self.encoder.enc_layers[0].num_heads_param,\n",
    "            \"dff\": self.encoder.enc_layers[0].dff_param,\n",
    "            \"input_vocab_size\": self.encoder.input_vocab_size,\n",
    "            \"target_vocab_size\": self.decoder.target_vocab_size,\n",
    "            \"pe_input\": self.encoder.maximum_position_encoding,\n",
    "            \"pe_target\": self.decoder.maximum_position_encoding,\n",
    "            \"rate\": self.encoder.rate,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "\n",
    "# --- 3. Training Steps ---\n",
    "\n",
    "# Hyperparameters (keep small for \"simple\" LLM)\n",
    "num_layers = 2\n",
    "d_model = 64 # Embedding dimension\n",
    "num_heads = 4\n",
    "dff = 128 # Hidden layer size in feed forward network\n",
    "dropout_rate = 0.1\n",
    "\n",
    "# Instantiate the Transformer model\n",
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=en_vocab_size,\n",
    "    target_vocab_size=fr_vocab_size,\n",
    "    pe_input=max_en_len,\n",
    "    pe_target=max_fr_len,\n",
    "    rate=dropout_rate\n",
    ")\n",
    "\n",
    "# Custom learning rate schedule (often used with Transformers)\n",
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(CustomSchedule, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "\n",
    "    def __call__(self, step):\n",
    "        # arg1 = tf.math.rsqrt(step)\n",
    "        arg1 = tf.math.rsqrt(tf.cast(step, tf.float32))\n",
    "        # arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        arg2 = tf.cast(step, tf.float32) * (self.warmup_steps ** -1.5)\n",
    "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            \"d_model\": self.d_model.numpy(),\n",
    "            \"warmup_steps\": self.warmup_steps,\n",
    "        }\n",
    "\n",
    "learning_rate = CustomSchedule(d_model)\n",
    "optimizer = Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9,clipnorm=1.0)\n",
    "\n",
    "# Loss function: SparseCategoricalCrossentropy as targets are integer IDs\n",
    "loss_object = SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    # Create a mask to ignore padding tokens (ID 0) from the loss calculation\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    # Apply the mask to the loss\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    # Return the mean loss, considering only non-padded tokens\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    # Calculate accuracy by comparing predicted token (argmax) with real token\n",
    "    # accuracies = tf.cast(tf.math.equal(real, tf.argmax(pred, axis=2)), tf.float32)\n",
    "    accuracies = tf.cast(tf.math.equal(real, tf.cast(tf.argmax(pred, axis=2), tf.int32)), tf.float32)\n",
    "    # Create a mask to ignore padding tokens (ID 0) from accuracy calculation\n",
    "    mask = tf.cast(tf.math.logical_not(tf.math.equal(real, 0)), tf.float32)\n",
    "    accuracies *= mask\n",
    "    return tf.reduce_sum(accuracies) / tf.reduce_sum(mask)\n",
    "\n",
    "transformer.compile(optimizer=optimizer, loss=loss_function, metrics=[accuracy_function])\n",
    "\n",
    "# Training\n",
    "epochs = 50 # Adjusted epochs for faster demo with larger dataset\n",
    "batch_size = 16 # Batch size can be larger now due to more data\n",
    "\n",
    "print(\"\\n--- Starting Training ---\")\n",
    "transformer.fit(\n",
    "    x=(encoder_input_data, decoder_input_data),\n",
    "    y=decoder_target_data,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"\\n--- Training Complete ---\")\n",
    "\n",
    "\n",
    "# --- 4. Inference (Translation) ---\n",
    "\n",
    "def evaluate(input_sentence):\n",
    "    input_sentence = preprocess_sentence(input_sentence)\n",
    "    \n",
    "    # Prepare encoder input\n",
    "    encoder_input = en_tokenizer.texts_to_sequences([input_sentence])\n",
    "    # Pad to the max_en_len used during training\n",
    "    encoder_input = pad_sequences(encoder_input, maxlen=max_en_len, padding='post', value=0)\n",
    "    \n",
    "    # Prepare decoder input (start with SOS token)\n",
    "    decoder_input = tf.expand_dims([fr_tokenizer.word_index[SOS_TOKEN]], 0)\n",
    "    \n",
    "    output_tokens = []\n",
    "\n",
    "    # Iterate up to max French length (or until EOS token is predicted)\n",
    "    for i in range(max_fr_len): \n",
    "        predictions = transformer([encoder_input, decoder_input], training=False)\n",
    "        \n",
    "        # Select the last token's prediction (the one currently being generated)\n",
    "        predictions = predictions[:, -1, :] \n",
    "\n",
    "        predicted_id = tf.argmax(predictions, axis=-1).numpy()[0]\n",
    "        \n",
    "        # Check if EOS token is predicted\n",
    "        if predicted_id == fr_tokenizer.word_index[EOS_TOKEN]:\n",
    "            break \n",
    "\n",
    "        # Append predicted ID to output tokens\n",
    "        output_tokens.append(predicted_id)\n",
    "        \n",
    "        # Concatenate the predicted ID to the decoder input for the next step\n",
    "        decoder_input = tf.concat([decoder_input, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    # Convert predicted IDs back to words\n",
    "    translated_sentence = []\n",
    "    for token_id in output_tokens:\n",
    "        word = fr_tokenizer.index_word.get(token_id, UNK_TOKEN)\n",
    "        # Avoid adding PAD_TOKEN itself to the translated sentence\n",
    "        if word != PAD_TOKEN: \n",
    "            translated_sentence.append(word)\n",
    "    \n",
    "    return \" \".join(translated_sentence)\n",
    "\n",
    "print(\"\\n--- Testing Translation ---\")\n",
    "\n",
    "test_sentences = [\n",
    "    \"I am a student.\",\n",
    "    \"How are you?\",\n",
    "    \"She likes cats.\",\n",
    "    \"We are learning machine translation.\",\n",
    "    \"The dog is brown.\",\n",
    "    \"He reads books.\",\n",
    "    \"Where is the library?\",\n",
    "    \"What is your name?\",\n",
    "    \"This is a test sentence.\",\n",
    "    \"Please translate this.\",\n",
    "    \"Hello world.\",\n",
    "    \"I love deep learning.\",\n",
    "    \"The quick brown fox.\" # A sentence likely not in the training data\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translated = evaluate(sentence)\n",
    "    print(f\"English: '{sentence}'\")\n",
    "    print(f\"French (Translated): '{translated}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5d5220-d045-40e9-b16a-4dab06f26fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Testing Translation ---\n",
      "English: 'it is unknown whether these differences persist .'\n",
      "French (Translated): 'e e pmid pmid pmid 24082400 la da la deux la prise la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la la'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Testing Translation ---\")\n",
    "\n",
    "test_sentences = [\n",
    "    \"it is unknown whether these differences persist .\"\n",
    "]\n",
    "\n",
    "for sentence in test_sentences:\n",
    "    translated = evaluate(sentence)\n",
    "    print(f\"English: '{sentence}'\")\n",
    "    print(f\"French (Translated): '{translated}'\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d870244-7001-4d1c-8b4a-155b6e195179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>English to French Translator</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ddd3bb19f547d09e59ca661a99f2ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Textarea(value='Type an English sentence here...', description='English:', layout=Layout(height='100px', width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e91da6d88f9e4668b818bfe6dec50058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='primary', description='Translate', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<b>Translation:</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6960141c7a143e2b357f8972d6964d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid black', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Create UI components\n",
    "input_box = widgets.Textarea(\n",
    "    value=\"Type an English sentence here...\",\n",
    "    description=\"English:\",\n",
    "    layout=widgets.Layout(width='100%', height='100px')\n",
    ")\n",
    "\n",
    "output_box = widgets.Output(layout=widgets.Layout(width='100%', border='1px solid black'))\n",
    "\n",
    "translate_button = widgets.Button(description=\"Translate\", button_style='primary')\n",
    "\n",
    "def on_translate_click(b):\n",
    "    output_box.clear_output()\n",
    "    user_input = input_box.value\n",
    "    translation = evaluate(user_input)\n",
    "    with output_box:\n",
    "        print(f\"Translated: {translation}\")\n",
    "\n",
    "translate_button.on_click(on_translate_click)\n",
    "\n",
    "# --- Display the UI ---\n",
    "display(HTML(\"<h3>English to French Translator</h3>\"))\n",
    "display(input_box)\n",
    "display(translate_button)\n",
    "display(HTML(\"<b>Translation:</b>\"))\n",
    "display(output_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4f636-6ac1-4396-817d-960f19c2def6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
