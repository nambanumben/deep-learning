{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc40df82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c9b5e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and Normalize CIFAR-10\n",
    "def normalize_images(train_images, test_images):\n",
    "    mean = np.mean(train_images, axis=(0, 1, 2, 3))\n",
    "    std = np.std(train_images, axis=(0, 1, 2, 3))\n",
    "    return (train_images - mean) / (std + 1e-7), (test_images - mean) / (std + 1e-7)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "x_train = x_train.astype(np.float32)\n",
    "x_test = x_test.astype(np.float32)\n",
    "x_train, x_test = normalize_images(x_train, x_test)\n",
    "\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94097098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "datagen.fit(x_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "330f4ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Custom VGG16 Model Class\n",
    "class ConvBNRelu(tf.keras.Model):\n",
    "    def __init__(self, filters, kernel_size=3, rate=0.4, drop=True):\n",
    "        super(ConvBNRelu, self).__init__()\n",
    "        self.drop = drop\n",
    "        self.conv = layers.Conv2D(filters, kernel_size, padding='same',\n",
    "                                  kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.batchnorm = layers.BatchNormalization()\n",
    "        self.dropout = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv(x)\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.batchnorm(x, training=training)\n",
    "        if self.drop:\n",
    "            x = self.dropout(x, training=training)\n",
    "        return x\n",
    "\n",
    "class VGG16Model(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(VGG16Model, self).__init__()\n",
    "        self.block1 = [ConvBNRelu(64, rate=0.3), ConvBNRelu(64, drop=False), layers.MaxPooling2D()]\n",
    "        self.block2 = [ConvBNRelu(128), ConvBNRelu(128, drop=False), layers.MaxPooling2D()]\n",
    "        self.block3 = [ConvBNRelu(256), ConvBNRelu(256), ConvBNRelu(256, drop=False), layers.MaxPooling2D()]\n",
    "        self.block4 = [ConvBNRelu(512), ConvBNRelu(512), ConvBNRelu(512, drop=False), layers.MaxPooling2D()]\n",
    "        self.block5 = [ConvBNRelu(512), ConvBNRelu(512), ConvBNRelu(512, drop=False), layers.MaxPooling2D()]\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.fc1 = layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0005))\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.fc2 = layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        for layer in self.block1 + self.block2 + self.block3 + self.block4 + self.block5:\n",
    "            x = layer(x, training=training) if isinstance(layer, ConvBNRelu) else layer(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn(x, training=training)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da4a7b56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vgg16' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Compile the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mvgg16\u001b[49m\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m      3\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m     loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Define early stopping callback\u001b[39;00m\n\u001b[1;32m      9\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m callbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(\n\u001b[1;32m     10\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m     12\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'vgg16' is not defined"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "vgg16.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Define early stopping callback\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = vgg16.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cc8af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Custom VGG16\n",
    "loss, acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Custom VGG16 Accuracy: {acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dc316",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained VGG16 Transfer Learning\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = VGG16(include_top=False, weights='imagenet', input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = base_model.output\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='relu')(x)\n",
    "x = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model_pretrained = Model(inputs=base_model.input, outputs=x)\n",
    "model_pretrained.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_pretrained.fit(x_train, y_train, batch_size=128, epochs=10, validation_data=(x_test, y_test), verbose=2)\n",
    "\n",
    "loss_pretrained, acc_pretrained = model_pretrained.evaluate(x_test, y_test)\n",
    "print(f\"Pretrained VGG16 Accuracy on CIFAR-10: {acc_pretrained:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
